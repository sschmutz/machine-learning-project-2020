## Presentation structure (suggestion)

- Introduction  
  - Newspapers can have different writing styles, can that not only subjectively be proven (what's our aim)?  
  - How the data was collected and what's the format  

- Natural Language Processing (NLP) basics  
  - Tokenization (can be one letter, word, or multiple words), aims to bring data in a format the computer can work with  
  - Document Term matrix

- Exploratory data analysis (first we looked at our datasets)  
  - Statistics (how many headlines/tesers are there and how many words do they consist of)  
  - Compare word frequencies  

- Proposed model  
  - Implementation  
  - Results/Performance (overfitting observed?)  
  - What could we do to improve?  

- Conclusions, outlook, limitations and challenges  
  - What other, more sophisticated tools could be used (e.g. RNN)  


### open questions
What's the time-frame of the presentation?  
Should we also discuss code or just concepts (or is it on us to decide)?  
Does everyone of the group have to present a part?  
